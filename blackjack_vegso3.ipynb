{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzKO-v37hHui"
      },
      "source": [
        "#### Episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT2EU5jNhHuk"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gym import spaces\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "import time\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AClrB1SlhHuk"
      },
      "outputs": [],
      "source": [
        "class BlackJackEnv(gym.Env):\n",
        "\n",
        "    metadata = {'render.modes':['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        self.observation_space = spaces.Discrete(2000000)\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.step_count = 0                        ### Number of actions taken in the game till now\n",
        "        self.double_count1 = 0\n",
        "        self.double_count2 = 0\n",
        "        self.stick_happened = False\n",
        "        self.can_split = 0\n",
        "        self.done_split = 0\n",
        "        self.stage = 1\n",
        "        self.actions = ['hit', 'stick', 'double_down', 'split']\n",
        "\n",
        "\n",
        "    def check_usable_ace(self,hand):\n",
        "        ### Creating a temporary hand taking the Ace's value as 11 to check of usability\n",
        "        temp_hand = hand.copy()\n",
        "\n",
        "        ### Checking if the hand has any ace, if not then returns False\n",
        "        if np.any(temp_hand == 1):\n",
        "            ### If the hand has any ace then replace the ace(1) with 11 in the temporary hand,\n",
        "            ### if there are more than one ace then replaces the first ace(1) with 11\n",
        "\n",
        "            temp_hand[np.where(temp_hand == 1)[0][0]] = 11\n",
        "\n",
        "            ### After replacement if sum is less than equal to 21, then the ace is usable\n",
        "            if temp_hand.sum() <= 21:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def use_ace(self,hand):\n",
        "        temp_hand = hand.copy()\n",
        "        temp_hand[np.where(temp_hand == 1)[0][0]] = 11\n",
        "        return temp_hand\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.double_count1 = 0\n",
        "        self.double_count2 = 0\n",
        "        self.can_split = 0\n",
        "        self.done_split = 0\n",
        "        self.stage = 1\n",
        "        self.stick_happened = False\n",
        "        distr = [1/13] * 9 + [4/13]\n",
        "        ### New Player Hand\n",
        "        self.current_hand1 = np.random.choice(range(1, 11), 2, p=distr)\n",
        "        self.current_hand2 = np.zeros(1, dtype=int)\n",
        "        if self.current_hand1[0] == self.current_hand1[1]:\n",
        "          self.can_split = 1\n",
        "\n",
        "        ### Initialising Usable Ace as False\n",
        "\n",
        "        self.usable_ace1 = False\n",
        "        self.usable_ace2 = False\n",
        "\n",
        "        ### Variable is used to inform whether the dealer has sticked,\n",
        "        ### Used to know when to terminate the game\n",
        "\n",
        "        self.dealer_stick = False\n",
        "\n",
        "\n",
        "        ### Checking if player hand has Usable Ace, if yes, then replacing it with 11.\n",
        "        if self.check_usable_ace(self.current_hand1):\n",
        "            self.usable_ace1 = True\n",
        "            self.current_hand1 = self.use_ace(self.current_hand1)\n",
        "\n",
        "        ### State variable Current Sum\n",
        "        self.current_sum1 = self.current_hand1.sum()\n",
        "        self.current_sum2 = 0\n",
        "\n",
        "        ### Dealer's New Hand\n",
        "        self.dealer_hand = np.random.choice(range(1, 11), 2, p=distr)\n",
        "\n",
        "        ### Dealer's Sum\n",
        "        self.dealer_sum = self.dealer_hand.sum()\n",
        "\n",
        "        ### State Variable: Dealer Showing Card\n",
        "        self.dealer_showing_card = self.dealer_hand[0]\n",
        "\n",
        "        ### Checking if Dealer's hand has Usable Ace, if yes, then replacing it with 11.\n",
        "        if self.check_usable_ace(self.dealer_hand):\n",
        "            temp_dealer_hand = self.use_ace(self.dealer_hand)\n",
        "            self.dealer_sum = temp_dealer_hand.sum()\n",
        "\n",
        "\n",
        "    def take_turn(self,player,hand,number):\n",
        "\n",
        "        if player == 'dealer':\n",
        "            distr = [1/13] * 9 + [4/13]\n",
        "            ### takes a new random card\n",
        "            new_card = np.random.choice(range(1, 11), p=distr)\n",
        "\n",
        "            ### adding new card to the players hand and making a temporary new hand\n",
        "            new_dealer_hand = np.array(hand.tolist() +  [new_card])\n",
        "\n",
        "            ### Check if there is usable ace\n",
        "            if self.check_usable_ace(new_dealer_hand):\n",
        "\n",
        "                ### replace ace(1) with 11\n",
        "                new_dealer_hand = self.use_ace(new_dealer_hand)\n",
        "\n",
        "            ### Assigning the temporary hand to the players actual hand\n",
        "            self.dealer_hand = new_dealer_hand\n",
        "\n",
        "            ### Updating the players hand sum variable\n",
        "            self.dealer_sum = self.dealer_hand.sum()\n",
        "\n",
        "        if player == 'player':\n",
        "            distr = [1/13] * 9 + [4/13]\n",
        "            ### takes a new random card\n",
        "            new_card = np.random.choice(range(1, 11), p=distr)\n",
        "\n",
        "            ### adding new card to the players hand and making a temporary new hand\n",
        "            new_player_hand = np.array(hand.tolist()+ [new_card])\n",
        "\n",
        "            ### Check if there is usable ace\n",
        "            if self.check_usable_ace(new_player_hand):\n",
        "\n",
        "                ### replace ace(1) with 11\n",
        "                self.usable_ace = True\n",
        "                new_player_hand = self.use_ace(new_player_hand)\n",
        "\n",
        "            if number == 1:\n",
        "              self.current_hand1 = new_player_hand\n",
        "              self.current_sum1 = self.current_hand1.sum()\n",
        "            elif number == 2:\n",
        "            ### Assigning the temporary hand to the players actual hand\n",
        "              self.current_hand2 = new_player_hand\n",
        "              ### Updating the players hand sum variable\n",
        "              self.current_sum2 = self.current_hand2.sum()\n",
        "\n",
        "\n",
        "\n",
        "    def check_game_status(self, dd1 = 0, dd2 = 0, mode = 'final'):\n",
        "\n",
        "        result = {'winner':'',\n",
        "                 'is_done1': False,\n",
        "                 'is_done2': False,\n",
        "                 'reward':0}\n",
        "\n",
        "        if mode == 'check':\n",
        "\n",
        "          if self.current_sum1 >= 21:\n",
        "            result['is_done1'] = True\n",
        "\n",
        "          if self.current_sum2 >= 21:\n",
        "            result['is_done2'] = True\n",
        "\n",
        "        elif mode == 'final':\n",
        "          if self.done_split == 0 and self.stage == 3:\n",
        "            dupla = 0\n",
        "            if dd1 == 0:\n",
        "              dupla = 1\n",
        "            else:\n",
        "              dupla = 2 * dd1\n",
        "\n",
        "            if self.current_sum1 > 21 and self.dealer_sum == 21 or self.dealer_sum == 21 and self.current_sum1 < 21 or self.dealer_sum < 21 and self.current_sum1 > 21:\n",
        "                  result['winner'] = 'dealer'\n",
        "                  result['is_done1'] = True\n",
        "                  result['is_done2'] = True\n",
        "                  result['reward'] = -1 * dupla\n",
        "            elif self.current_sum1 == 21 and self.dealer_sum > 21 or self.dealer_sum < 21 and self.current_sum1 == 21 or self.dealer_sum > 21 and self.current_sum1 < 21:\n",
        "                  result['winner'] = 'player'\n",
        "                  result['is_done1'] = True\n",
        "                  result['is_done2'] = True\n",
        "                  result['reward'] = 1 * dupla\n",
        "\n",
        "            elif self.current_sum1 == 21 and self.dealer_sum == 21 or self.dealer_sum > 21 and self.current_sum1 > 21:\n",
        "                  result['winner'] = 'draw'\n",
        "                  result['is_done1'] = True\n",
        "                  result['is_done2'] = True\n",
        "                  result['reward'] = 0\n",
        "\n",
        "            else:\n",
        "              result['is_done1'] = True\n",
        "              result['is_done2'] = True\n",
        "              diff_21_player = 21 - self.current_sum1\n",
        "              diff_21_dealer = 21 - self.dealer_sum\n",
        "\n",
        "              if diff_21_player > diff_21_dealer:\n",
        "                  result['reward'] = -1 * dupla\n",
        "                  result['winner'] = 'dealer'\n",
        "              elif diff_21_player < diff_21_dealer:\n",
        "                  result['reward'] = 1 * dupla\n",
        "                  result['winner'] = 'player'\n",
        "              else:\n",
        "                  result['reward'] = 0\n",
        "                  result['winner'] = 'draw'\n",
        "\n",
        "              return result\n",
        "\n",
        "            return result\n",
        "\n",
        "          elif self.done_split == 1 and self.stage == 3:\n",
        "            dupla1 = 0\n",
        "            dupla2 = 0\n",
        "            if dd1 == 0:\n",
        "              dupla1 = 1\n",
        "            else:\n",
        "              dupla1 = 2 * dd1\n",
        "            if dd2 == 0:\n",
        "              dupla2 = 1\n",
        "            else:\n",
        "              dupla2 = 2 * dd2\n",
        "\n",
        "            #if mode == 'normal':\n",
        "            if self.current_sum1 == 21 and self.current_sum2 == 21 and self.dealer_sum == 21 or self.current_sum1 > 21 and self.current_sum2 > 21 and self.dealer_sum > 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 0\n",
        "                result['winner'] = 'draw'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum > 21 and self.current_sum1 <= 21 and self.current_sum2 <= 21 or self.current_sum1 == 21 and self.current_sum2 == 21 and self.dealer_sum < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 1 * dupla1 + 1 * dupla2\n",
        "                result['winner'] = 'player'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum == 21 and self.current_sum1 < 21 and self.current_sum2 < 21 or self.dealer_sum <= 21 and self.current_sum1 > 21 and self.current_sum2 > 21 or self.dealer_sum == 21 and self.current_sum1 < 21 and self.current_sum2 > 21 or self.dealer_sum == 21 and self.current_sum1 > 21 and self.current_sum2 < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = -1 * dupla1 -1 * dupla2\n",
        "                result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum == 21 and self.current_sum1 < 21 and self.current_sum2 == 21 or self.dealer_sum == 21 and self.current_sum1 > 21 and self.current_sum2 == 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = -1 * dupla1\n",
        "                result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum == 21 and self.current_sum1 == 21 and self.current_sum2 < 21 or self.dealer_sum == 21 and self.current_sum1 == 21 and self.current_sum2 > 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = -1 * dupla2\n",
        "                result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum > 21 and self.current_sum1 < 21 and self.current_sum2 > 21 or self.dealer_sum > 21 and self.current_sum1 == 21 and self.current_sum2 > 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 1 * dupla1\n",
        "                result['winner'] = 'player'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum > 21 and self.current_sum1 > 21 and self.current_sum2 < 21 or self.dealer_sum > 21 and self.current_sum1 > 21 and self.current_sum2 == 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 1 * dupla2\n",
        "                result['winner'] = 'player'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 == 21 and self.current_sum2 > 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 1 * dupla1 - 1 * dupla2\n",
        "                if 1 * dupla1 - 1 * dupla2 > 0:\n",
        "                    result['winner'] = 'player'\n",
        "                elif 1 * dupla1 - 1 * dupla2 == 0:\n",
        "                    result['winner'] = 'draw'\n",
        "                else:\n",
        "                    result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 > 21 and self.current_sum2 == 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = -1 * dupla1 + 1 * dupla2\n",
        "                if -1 * dupla1 + 1 * dupla2 > 0:\n",
        "                    result['winner'] = 'player'\n",
        "                elif -1 * dupla1 + 1 * dupla2 == 0:\n",
        "                    result['winner'] = 'draw'\n",
        "                else:\n",
        "                    result['winner'] = 'dealer'\n",
        "                return result\n",
        "    #ez az alsó 4 a ?-es\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 > 21 and self.current_sum2 < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                if self.current_sum2 - self.dealer_sum > 0:\n",
        "                    result['reward'] = -1 * dupla1 + 1 * dupla2\n",
        "                    if -1 * dupla1 + 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif -1 * dupla1 + 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                elif self.current_sum2 - self.dealer_sum == 0:\n",
        "                    result['winner'] = 'dealer'\n",
        "                    result['reward'] = -1 * dupla1\n",
        "                else:\n",
        "                    result['winner'] = 'dealer'\n",
        "                    result['reward'] = -1 * dupla1 - 1 * dupla2\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 < 21 and self.current_sum2 > 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                if self.current_sum1 - self.dealer_sum > 0:\n",
        "                    result['reward'] = 1 * dupla1 - 1 * dupla2\n",
        "                    if 1 * dupla1 - 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif 1 * dupla1 - 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                elif self.current_sum1 - self.dealer_sum == 0:\n",
        "                    result['winner'] = 'dealer'\n",
        "                    result['reward'] = -1 * dupla2\n",
        "                else:\n",
        "                    result['winner'] = 'dealer'\n",
        "                    result['reward'] = -1 * dupla1 - 1 * dupla2\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 < 21 and self.current_sum2 == 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                if self.current_sum1 - self.dealer_sum > 0:\n",
        "                    result['reward'] = 1 * dupla1 + 1 * dupla2\n",
        "                    result['winner'] = 'player'\n",
        "                elif self.current_sum1 - self.dealer_sum == 0:\n",
        "                    result['winner'] = 'player'\n",
        "                    result['reward'] = 1 * dupla2\n",
        "                else:\n",
        "                    result['reward'] = -1 * dupla1 + 1 * dupla2\n",
        "                    if -1 * dupla1 + 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif -1 * dupla1 + 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum < 21 and self.current_sum1 == 21 and self.current_sum2 < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                if self.current_sum2 - self.dealer_sum > 0:\n",
        "                    result['reward'] = 1 * dupla1 + 1 * dupla2\n",
        "                    result['winner'] = 'player'\n",
        "                elif self.current_sum2 - self.dealer_sum == 0:\n",
        "                    result['winner'] = 'player'\n",
        "                    result['reward'] = 1 * dupla1\n",
        "                else:\n",
        "                    result['reward'] = 1 * dupla1 - 1 * dupla2\n",
        "                    if 1 * dupla1 - 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif 1 * dupla1 - 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            #elif mode == 'compare':\n",
        "            else:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                diff_21_player1 = 21 - self.current_sum1\n",
        "                diff_21_player2 = 21 - self.current_sum2\n",
        "                diff_21_dealer = 21 - self.dealer_sum\n",
        "\n",
        "                if diff_21_player1 > diff_21_dealer and diff_21_player2 > diff_21_dealer:\n",
        "                    result['winner'] = 'dealer'\n",
        "                    result['reward'] = -1 * dupla1 - 1 * dupla2\n",
        "                elif diff_21_player1 < diff_21_dealer and diff_21_player2 < diff_21_dealer:\n",
        "                    result['winner'] = 'player'\n",
        "                    result['reward'] = 1 * dupla1 + 1 * dupla2\n",
        "                elif diff_21_player1 < diff_21_dealer and diff_21_player2 > diff_21_dealer:\n",
        "                    result['reward'] = 1 * dupla1 - 1 * dupla2\n",
        "                    if 1 * dupla1 - 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif 1 * dupla1 - 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                else:\n",
        "                    result['reward'] = -1 * dupla1 + 1 * dupla2\n",
        "                    if 1 * dupla1 - 1 * dupla2 > 0:\n",
        "                        result['winner'] = 'player'\n",
        "                    elif 1 * dupla1 - 1 * dupla2 == 0:\n",
        "                        result['winner'] = 'draw'\n",
        "                    else:\n",
        "                        result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "        return result\n",
        "\n",
        "    def step(self,action):\n",
        "\n",
        "        self.step_count += 1  ### Number of actions taken in the game till now\n",
        "\n",
        "        result = {'winner':'',\n",
        "                 'is_done1': False,\n",
        "                 'is_done2': False,\n",
        "                 'reward':0}\n",
        "\n",
        "        ### Before taking the first step of the game we need to check for \"natural\"\n",
        "        ### winning condition if the initial two cards of the players are 21\n",
        "        ### If anyone has 21, then that player wins, if both have 21, then the game is\n",
        "        ### drawn. Otherwise the game will continue\n",
        "\n",
        "\n",
        "        if self.stage == 1:\n",
        "\n",
        "          if self.step_count == 1:\n",
        "            if self.check_usable_ace(self.current_hand1):\n",
        "                self.current_hand1 = self.use_ace(self.current_hand1)\n",
        "            if self.check_usable_ace(self.dealer_hand):\n",
        "                self.dealer_hand = self.use_ace(self.dealer_hand)\n",
        "\n",
        "            if self.current_sum1 == 21 and self.dealer_sum == 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 0\n",
        "                result['winner'] = 'draw'\n",
        "                return result\n",
        "\n",
        "            elif self.current_sum1 == 21 and self.dealer_sum < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = 1\n",
        "                result['winner'] = 'player'\n",
        "                return result\n",
        "\n",
        "            elif self.dealer_sum == 21 and self.current_sum1 < 21:\n",
        "                result['is_done1'] = True\n",
        "                result['is_done2'] = True\n",
        "                result['reward'] = -1\n",
        "                result['winner'] = 'dealer'\n",
        "                return result\n",
        "\n",
        "            if self.dealer_sum >= 17:\n",
        "                self.dealer_stick = True\n",
        "\n",
        "          if action == 0:\n",
        "\n",
        "            if self.done_split == 0:\n",
        "              ### Player Takes Turn\n",
        "              self.take_turn('player', self.current_hand1, 1)\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              if result['is_done1'] == True:\n",
        "                self.stage = 3\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "                result['is_done2'] = True\n",
        "                return result\n",
        "\n",
        "            else:\n",
        "              self.take_turn('player', self.current_hand1, 1)\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              if result['is_done1'] == True:\n",
        "                self.stage = 2\n",
        "                self.take_turn('player', self.current_hand2, 2)\n",
        "                return result\n",
        "\n",
        "\n",
        "          if action == 1:\n",
        "\n",
        "            if self.done_split == 0:\n",
        "              if self.stick_happened == False:\n",
        "                self.stick_happened = True\n",
        "              if self.dealer_stick == True:\n",
        "                return self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "\n",
        "              while self.dealer_sum < 17:\n",
        "                self.take_turn('dealer', self.dealer_hand, 0)\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              self.dealer_stick = True\n",
        "              self.stage = 3\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "              return result\n",
        "\n",
        "\n",
        "            else:\n",
        "              self.stage = 2\n",
        "              self.take_turn('player', self.current_hand2, 2)\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              result['is_done1'] = True\n",
        "              return result\n",
        "\n",
        "          if action ==2: ### double down\n",
        "\n",
        "            if self.done_split == 0:\n",
        "              self.double_count1 = 1\n",
        "              ### Player Takes Turn\n",
        "              self.take_turn('player', self.current_hand1, 1)\n",
        "              if self.dealer_stick == True:  ### if dealer has already sticked\n",
        "                    return self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "              while self.dealer_sum < 17:\n",
        "                self.take_turn('dealer', self.dealer_hand, 0)\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              self.stage = 3\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "              return result\n",
        "            else:\n",
        "              self.double_count1 = 1\n",
        "              self.take_turn('player', self.current_hand1, 1)\n",
        "              self.stage = 2\n",
        "              self.take_turn('player', self.current_hand2, 2)\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              return result\n",
        "\n",
        "\n",
        "          if action == 3 and self.can_split == 1 and self.done_split != 1: ### split\n",
        "            self.can_split = 0\n",
        "            self.done_split = 1\n",
        "            elso_elem = np.array([self.current_hand1[0]], dtype=self.current_hand1.dtype)\n",
        "            masodik_elem = np.array([self.current_hand1[1]], dtype=self.current_hand1.dtype)\n",
        "            self.current_hand1 = elso_elem\n",
        "            self.current_hand2 = masodik_elem\n",
        "            self.take_turn('player', self.current_hand1, 1)\n",
        "            ### Checking game status\n",
        "            result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "            return result\n",
        "\n",
        "        elif self.stage == 2:\n",
        "\n",
        "          if action == 0:\n",
        "\n",
        "            self.take_turn('player', self.current_hand2, 2)\n",
        "\n",
        "            ### Checking game status\n",
        "            result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "            if result['is_done2'] == True:\n",
        "                #return result\n",
        "                while self.dealer_sum < 17:\n",
        "                    self.take_turn('dealer', self.dealer_hand, 0)\n",
        "                    result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "                self.stage = 3\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "                #result['is_done1'] = True\n",
        "                return result\n",
        "\n",
        "\n",
        "\n",
        "          if action == 1:  ### stick\n",
        "\n",
        "              if self.stick_happened == False:\n",
        "                self.stick_happened = True\n",
        "              ### Dealers Turn\n",
        "              while self.dealer_sum < 17:\n",
        "                self.take_turn('dealer', self.dealer_hand, 0)\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              self.stage = 3\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "              result['is_done2'] = True\n",
        "              return result\n",
        "\n",
        "\n",
        "          if action == 2: ### double down\n",
        "\n",
        "              self.double_count2 = 1\n",
        "              ### Player Takes Turn\n",
        "              self.take_turn('player', self.current_hand2, 2)\n",
        "\n",
        "              ### Dealers Turn\n",
        "              while self.dealer_sum < 17:\n",
        "                self.take_turn('dealer', self.dealer_hand, 0)\n",
        "                result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'check')\n",
        "              self.stage = 3\n",
        "              result = self.check_game_status(dd1 = self.double_count1, dd2 = self.double_count2, mode = 'final')\n",
        "              result['is_done2'] = True\n",
        "              return result\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_current_state(self):\n",
        "        '''\n",
        "        returns the current state variables, current_sum, dealer_showing_card, usable_ace\n",
        "        '''\n",
        "        current_state = {}\n",
        "\n",
        "        current_state['current_sum1'] = self.current_sum1\n",
        "        current_state['current_sum2'] = self.current_sum2\n",
        "        current_state['dealer_showing_card'] = self.dealer_showing_card\n",
        "        current_state['stage'] = self.stage\n",
        "        current_state['usable_ace1'] = self.usable_ace1\n",
        "        current_state['usable_ace2'] = self.usable_ace2\n",
        "        current_state['stick_happened'] = self.stick_happened\n",
        "        current_state['double_count1'] = self.double_count1\n",
        "        current_state['double_count2'] = self.double_count2\n",
        "        current_state['can_split'] = self.can_split\n",
        "        current_state['done_split'] = self.done_split\n",
        "\n",
        "        return current_state\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "\n",
        "        print('OBSERVABLE STATES')\n",
        "        print('Current Sum 1 - {}'.format(self.current_sum1))\n",
        "        print('Current Sum 2 - {}'.format(self.current_sum2))\n",
        "        print('Dealer Showing Card - {}'.format(self.dealer_showing_card))\n",
        "        print('Stage - {}'.format(self.stage))\n",
        "        print('Usable Ace1 - {}'.format(self.usable_ace1))\n",
        "        print('Usable Ace2 - {}'.format(self.usable_ace2))\n",
        "        print('Stick happened - {}'.format(self.stick_happened))\n",
        "        print('Double down 1 - {}'.format(self.double_count1))\n",
        "        print('Double down 2 - {}'.format(self.double_count2))\n",
        "        print('Can split - {}'.format(self.can_split))\n",
        "        print('Done split - {}'.format(self.done_split))\n",
        "\n",
        "        print('AUXILLARY INFORMATION ------------------------------')\n",
        "        print('Current Hand 1 - {}'.format(self.current_hand1))\n",
        "        print('Current Hand 2 - {}'.format(self.current_hand2))\n",
        "        print('Dealer Hand - {}'.format(self.dealer_hand))\n",
        "        print('Dealer Sum - {}'.format(self.dealer_sum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEkr4TVhhHum"
      },
      "outputs": [],
      "source": [
        "bj = BlackJackEnv() #a double down miatt mindig újra kell ezt indítani"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jjqJvXYhHum",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "bj.reset()\n",
        "bj.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvFKDXLKhHun"
      },
      "outputs": [],
      "source": [
        "print(bj.step(1))\n",
        "bj.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLU_MEuhHup"
      },
      "source": [
        "#### Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjGEopHzhHup"
      },
      "outputs": [],
      "source": [
        "#### following are 4 dictionaries which help in converting the\n",
        "#### state values like current_sum and action to indexes in the Q value table\n",
        "\n",
        "current_sum_to_index1 = dict(zip(np.arange(4,33),np.arange(29)))\n",
        "current_sum_to_index2 = dict(zip(np.arange(4,33),np.arange(1,30)))\n",
        "current_sum_to_index2 = {0: 0, **current_sum_to_index2}\n",
        "dealer_showing_card_to_index = dict(zip(np.arange(1,11),np.arange(10)))\n",
        "stage_index = dict(zip(np.arange(1,4),np.arange(3)))\n",
        "usable_ace_index1 = dict(zip([False,True],[0,1]))\n",
        "usable_ace_index2 = dict(zip([False,True],[0,1]))\n",
        "stick_happened_index = dict(zip([False,True],[0,1]))\n",
        "double_count_index1 = dict(zip(np.arange(0,2),np.arange(2)))\n",
        "double_count_index2 = dict(zip(np.arange(0,2),np.arange(2)))\n",
        "can_split_index = dict(zip(np.arange(0,2),np.arange(2)))\n",
        "done_split_index = dict(zip(np.arange(0,2),np.arange(2)))\n",
        "action_index = dict(zip(['hit','stick', 'double_down', 'split'],[0,1,2,3]))\n",
        "\n",
        "def get_state_q_indices(current_state):\n",
        "\n",
        "    '''\n",
        "    used to get indices of the Q table for any given state\n",
        "\n",
        "    '''\n",
        "    current_sum_idx1 = current_sum_to_index1[current_state['current_sum1']]\n",
        "    current_sum_idx2 = current_sum_to_index2[current_state['current_sum2']]\n",
        "    dealer_showing_card_idx = dealer_showing_card_to_index[current_state['dealer_showing_card']]\n",
        "    stage_idx = stage_index[current_state['stage']]\n",
        "    usable_ace_idx1 = usable_ace_index1[current_state['usable_ace1']]\n",
        "    usable_ace_idx2 = usable_ace_index2[current_state['usable_ace2']]\n",
        "    stick_happened_idx = stick_happened_index[current_state['stick_happened']]\n",
        "    double_count_idx1 = double_count_index1[current_state['double_count1']]\n",
        "    double_count_idx2 = double_count_index2[current_state['double_count2']]\n",
        "    can_split_idx = can_split_index[current_state['can_split']]\n",
        "    done_split_idx = done_split_index[current_state['done_split']]\n",
        "\n",
        "    return [current_sum_idx1,current_sum_idx2,dealer_showing_card_idx,stage_idx,usable_ace_idx1,usable_ace_idx2,stick_happened_idx,double_count_idx1,double_count_idx2,can_split_idx,done_split_idx]\n",
        "\n",
        "def get_max_action(Q_sa, current_state):\n",
        "\n",
        "    '''\n",
        "    used to get the action with the max q-value given the current state and the Q table\n",
        "\n",
        "    '''\n",
        "\n",
        "    state_q_idxs = get_state_q_indices(current_state)\n",
        "    action = Q_sa[state_q_idxs[0],state_q_idxs[1],state_q_idxs[2],state_q_idxs[3],state_q_idxs[4],state_q_idxs[5],state_q_idxs[6],state_q_idxs[7],state_q_idxs[8],state_q_idxs[9],state_q_idxs[10],:].argmax()\n",
        "\n",
        "    return action\n",
        "\n",
        "def get_q_value(Q_sa, state, action):\n",
        "    '''\n",
        "    used to get Q value for any given state and action, given the Q table\n",
        "\n",
        "    '''\n",
        "    state_q_idxs = get_state_q_indices(state)\n",
        "    q_value = Q_sa[state_q_idxs[0],state_q_idxs[1],state_q_idxs[2],state_q_idxs[3],state_q_idxs[4],state_q_idxs[5],state_q_idxs[6],state_q_idxs[7],state_q_idxs[8],state_q_idxs[9],state_q_idxs[10],action]\n",
        "\n",
        "    return q_value\n",
        "#print(current_sum_to_index2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28M9NgjghHuq"
      },
      "outputs": [],
      "source": [
        "### first dimension  - current sum 1 (4-30)\n",
        "### second dimension - current sum 2 (0, 4-30)\n",
        "### third dimension  - dealers showing card (1-10)\n",
        "### fourth dimension - stage (1-3)\n",
        "### fifth dimension - usable ace 1 (False,True)\n",
        "### sixth dimension - usable ace 2 (False,True)\n",
        "### seventh dimension - stick happened (False,True)\n",
        "### eighth dimension - double down 1 (0,1)\n",
        "### ninth dimension - double down 2 (0,1)\n",
        "### tenth dimension - can split (0,1)\n",
        "### eleventh dimension - split done (0,1)\n",
        "### twelfth dimension - action (hit, stick, double down, split)\n",
        "\n",
        "Q_opt = np.zeros((29, 30, 10, 3, 2, 2, 2, 2, 2, 2, 2, 4)) #### Initializing the Q value Table with zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYL-4ssxhHuq"
      },
      "outputs": [],
      "source": [
        "episode_count = 0\n",
        "total_episodes = 100000\n",
        "gamma = 0.9             #### the discount factor\n",
        "alpha = 0.1             #### learning rate\n",
        "bj = BlackJackEnv()\n",
        "\n",
        "# Initialize variables for tracking runtime and errors\n",
        "start_time = time.time()\n",
        "\n",
        "while episode_count < total_episodes:\n",
        "\n",
        "\n",
        "    bj.reset()  ### Initialize S (the environment's starting state)\n",
        "\n",
        "\n",
        "    current_state = bj.get_current_state()\n",
        "    current_action = get_max_action(Q_opt, current_state)\n",
        "\n",
        "\n",
        "    ### Take Action\n",
        "    step_result = bj.step(current_action)\n",
        "\n",
        "    next_state = bj.get_current_state()\n",
        "    next_max_action = get_max_action(Q_opt, next_state)\n",
        "    immediate_reward = step_result['reward']\n",
        "\n",
        "\n",
        "\n",
        "    next_state_q_idxs = get_state_q_indices(next_state)\n",
        "\n",
        "    #### Get Q value for the next state and max action in the next state\n",
        "    q_max_s_a = get_q_value(Q_opt, next_state, next_max_action)\n",
        "\n",
        "    td_target = immediate_reward + gamma * q_max_s_a\n",
        "\n",
        "    #### Getting Q value for the current state and action\n",
        "    q_current_s_a = get_q_value(Q_opt, current_state, current_action)\n",
        "\n",
        "    td_error = td_target - q_current_s_a\n",
        "\n",
        "    state_q_idxs = get_state_q_indices(current_state)\n",
        "    #print(state_q_idxs)\n",
        "    #print(q_current_s_a + alpha*td_error)\n",
        "    #### Updating current Q(S,A)\n",
        "    Q_opt[state_q_idxs[0],state_q_idxs[1],state_q_idxs[2],state_q_idxs[3],state_q_idxs[4],state_q_idxs[5],state_q_idxs[6],state_q_idxs[7],state_q_idxs[8],state_q_idxs[9],state_q_idxs[10],current_action] = q_current_s_a + alpha*td_error\n",
        "\n",
        "    current_state = next_state  ### S=S'\n",
        "\n",
        "    if step_result['is_done1'] and step_result['is_done2']:\n",
        "        episode_count+=1\n",
        "\n",
        "        if episode_count%10000 == 0:\n",
        "            print('---------Episode - {} -----------'.format(episode_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m8fGwimhKtf"
      },
      "outputs": [],
      "source": [
        "Q_opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILXd2gPKmo9r"
      },
      "outputs": [],
      "source": [
        "Q = np.zeros((29, 30, 10, 3, 2, 2, 2, 2, 2, 2, 2, 4))\n",
        "episode_count = 0\n",
        "total_episodes = 100000\n",
        "gamma = 0.9             #### the discount factor\n",
        "alpha = 0.1             #### learning rate\n",
        "bj = BlackJackEnv()\n",
        "\n",
        "# Initialize variables for tracking runtime and errors\n",
        "start_time = time.time()\n",
        "diffs = []\n",
        "\n",
        "\n",
        "while episode_count < total_episodes:\n",
        "\n",
        "\n",
        "    bj.reset()  ### Initialize S (the environment's starting state)\n",
        "\n",
        "\n",
        "    current_state = bj.get_current_state()\n",
        "    current_action = get_max_action(Q, current_state)\n",
        "\n",
        "\n",
        "    ### Take Action\n",
        "    step_result = bj.step(current_action)\n",
        "\n",
        "    next_state = bj.get_current_state()\n",
        "    next_max_action = get_max_action(Q, next_state)\n",
        "    immediate_reward = step_result['reward']\n",
        "\n",
        "    next_state_q_idxs = get_state_q_indices(next_state)\n",
        "\n",
        "    #### Get Q value for the next state and max action in the next state\n",
        "    q_max_s_a = get_q_value(Q, next_state, next_max_action)\n",
        "    #print(immediate_reward)\n",
        "    td_target = immediate_reward + gamma * q_max_s_a\n",
        "\n",
        "    #### Getting Q value for the current state and action\n",
        "    q_current_s_a = get_q_value(Q, current_state, current_action)\n",
        "\n",
        "    td_error = td_target - q_current_s_a\n",
        "\n",
        "    state_q_idxs = get_state_q_indices(current_state)\n",
        "\n",
        "    #### Updating current Q(S,A)\n",
        "    Q[state_q_idxs[0],state_q_idxs[1],state_q_idxs[2],state_q_idxs[3],state_q_idxs[4],state_q_idxs[5],state_q_idxs[6],state_q_idxs[7],state_q_idxs[8],state_q_idxs[9],state_q_idxs[10],current_action] = q_current_s_a + alpha*td_error\n",
        "\n",
        "    current_state = next_state  ### S=S'\n",
        "\n",
        "    if step_result['is_done1'] and  step_result['is_done2']:\n",
        "        episode_count+=1\n",
        "        diffs.append(np.max(np.abs(Q_opt - Q)))\n",
        "        #print(np.max(np.abs(Q_opt - Q)))\n",
        "\n",
        "        if episode_count%10000 == 0:\n",
        "            print('---------Episode - {} -----------'.format(episode_count))\n",
        "\n",
        "# Calculate total runtime\n",
        "end_time = time.time()\n",
        "runtime = end_time - start_time\n",
        "\n",
        "print(f\"Total runtime: {runtime} seconds\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(diffs)\n",
        "#plt.plot(range(1, len(deltas)+1), deltas)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Delta')\n",
        "plt.title('Convergence of Q Learning'),\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"q_learning.jpg\", format=\"jpg\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAlfokzW7QBW"
      },
      "outputs": [],
      "source": [
        "print(len(diffs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAi97oXEhHur"
      },
      "source": [
        "#### SARSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRzWfz9hHur"
      },
      "outputs": [],
      "source": [
        "def get_action_epsilon_greedy(Q_sa, current_state, epsilon):\n",
        "    '''\n",
        "    Get action using epsilon-greedy policy.\n",
        "    '''\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.choice([0, 1])  # random action\n",
        "    else:\n",
        "        return get_max_action(Q_sa, current_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu6bvkiUhHus"
      },
      "outputs": [],
      "source": [
        "Q = np.zeros((29, 30, 10, 3, 2, 2, 2, 2, 2, 2, 2, 4)) #### Initializing the Q value Table with zeros\n",
        "episode_count = 0\n",
        "total_episodes = 1000\n",
        "gamma = 0.9             #### the discount factor\n",
        "alpha = 0.1             #### learning rate\n",
        "epsilon = 0.1           #### epsilon for epsilon-greedy policy\n",
        "bj = BlackJackEnv()\n",
        "\n",
        "# Initialize variables for tracking runtime and errors\n",
        "start_time = time.time()\n",
        "diffs2 = []\n",
        "\n",
        "while episode_count < total_episodes:\n",
        "    bj.reset()  ### Initialize S (the environment's starting state)\n",
        "\n",
        "    current_state = bj.get_current_state()\n",
        "    current_action = get_action_epsilon_greedy(Q, current_state, epsilon)\n",
        "\n",
        "    step_result = bj.step(current_action)\n",
        "\n",
        "    next_state = bj.get_current_state()\n",
        "    next_action = get_action_epsilon_greedy(Q, next_state, epsilon)\n",
        "    immediate_reward = step_result['reward']\n",
        "\n",
        "\n",
        "    q_current_s_a = get_q_value(Q, current_state, current_action)\n",
        "    q_next_s_a = get_q_value(Q, next_state, next_action)\n",
        "\n",
        "    td_target = immediate_reward + gamma * q_next_s_a\n",
        "    td_error = td_target - q_current_s_a\n",
        "\n",
        "    Q_state_idxs = get_state_q_indices(current_state)\n",
        "    Q[state_q_idxs[0],state_q_idxs[1],state_q_idxs[2],state_q_idxs[3],state_q_idxs[4],state_q_idxs[5],state_q_idxs[6],state_q_idxs[7],state_q_idxs[8],state_q_idxs[9],state_q_idxs[10], current_action] = q_current_s_a + alpha * td_error\n",
        "\n",
        "    current_state = next_state  ### S=S'\n",
        "    current_action = next_action  ### A=A'\n",
        "\n",
        "\n",
        "    if step_result['is_done1'] and  step_result['is_done2']:\n",
        "        episode_count+=1\n",
        "        diffs2.append(np.max(np.abs(Q_opt - Q)))\n",
        "\n",
        "        if episode_count%100 == 0:\n",
        "            print('---------Episode - {} -----------'.format(episode_count))\n",
        "\n",
        "# Calculate total runtime\n",
        "end_time = time.time()\n",
        "runtime = end_time - start_time\n",
        "\n",
        "print(f\"Total runtime: {runtime} seconds\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(diffs2)\n",
        "#plt.plot(range(1, len(deltas)+1), deltas)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Delta')\n",
        "plt.title('Convergence of SARSA')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"sarsa.jpg\", format=\"jpg\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1asOgQ5tn8Ky"
      },
      "source": [
        "###MDP solution approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb31RM4xKBui"
      },
      "outputs": [],
      "source": [
        "class Sol_Env(gym.Env):\n",
        "    def __init__(self):\n",
        "        # Define ranges for each state variable\n",
        "        self.player_sum_1_range = range(4, 32)  # Current sum 1, maybe 31?\n",
        "        self.player_sum_2_range = [0] + list(range(4, 32))  # Current sum 2, maybe 31?\n",
        "        self.dealer_sum_range = range(4, 29)  # Example range for dealer sum, maybe 27?\n",
        "        self.stage_range = range(1, 4)  # Stages 1, 2, 3\n",
        "        self.usable_ace_1 = [False, True]  # Usable ace for hand 1\n",
        "        self.usable_ace_2 = [False, True]  # Usable ace for hand 2\n",
        "        self.stick_happened = [False, True]  # Usable ace for the dealer\n",
        "        self.double_down_1 = [0, 1]  # Double down status for hand 1\n",
        "        self.double_down_2 = [0, 1]  # Double down status for hand 2\n",
        "        self.can_split = [0, 1]  # Whether split is possible\n",
        "        self.split_done = [0, 1]  # Whether split has been done\n",
        "\n",
        "        # Define actions\n",
        "        self.actions = ['hit', 'stick', 'double_down', 'split']\n",
        "\n",
        "    def get_all_states(self):\n",
        "        \"\"\"Generate all possible states.\"\"\"\n",
        "        states = list(product(\n",
        "            self.player_sum_1_range,  # Current sum 1\n",
        "            self.player_sum_2_range,  # Current sum 2\n",
        "            self.dealer_sum_range,  # Dealer's showing card\n",
        "            self.stage_range,  # Stage\n",
        "            self.usable_ace_1,  # Usable ace for hand 1\n",
        "            self.usable_ace_2,  # Usable ace for hand 2\n",
        "            self.stick_happened,   # Usable ace for the dealer\n",
        "            self.double_down_1,  # Double down status for hand 1\n",
        "            self.double_down_2,  # Double down status for hand 2\n",
        "            self.can_split,  # Can split\n",
        "            self.split_done  # Split done\n",
        "        ))\n",
        "        # Apply filters to exclude invalid states\n",
        "        filtered_states = [\n",
        "            state for state in states\n",
        "            if not (state[9] == 1 and state[10] == 1)  # Filter out states where can_split = 1 and split_done = 1\n",
        "            and not (state[1] == 0 and state[3] == 2)  # Filter out states where player_sum_2 = 0 and stage = 2\n",
        "            and not (state[10] == 0 and state[1] != 0)  # Filter out states where split_done = 0 but player_sum_2 != 0\n",
        "            and not (state[10] == 1 and state[1] == 0)  # Filter out states where split_done = 1 but player_sum_2 == 0\n",
        "            and not (state[0] < 10 and state[4])  # Filter out states where player_sum_1 < 10 but usable_ace_1 is True\n",
        "            and not (state[1] < 10 and state[5])  # Filter out states where player_sum_2 < 10 but usable_ace_2 is True\n",
        "            #and not (state[1] == 0 and state[5] )   Filter out states where player_sum_2 = 0 and usable_ace_2 = True\n",
        "            and not (state[1] == 0 and state[8] == 1)  # Filter out states where player_sum_2 = 0 and double_down_2 = 1\n",
        "            and not (state[3] == 1 and state[7] == 1 and state[8] == 1 or state[3] == 2 and state[7] == 1 and state[8] == 1)\n",
        "            and not (state[3] == 1 and state[7] == 0 and state[8] == 1)\n",
        "                           ]\n",
        "        return filtered_states\n",
        "\n",
        "    def get_possible_actions(self, state):\n",
        "        \"\"\"Return possible actions for a given state.\"\"\"\n",
        "        player_sum_1_range, _, _, stage, _, _, _, _, _, can_split, _ = state\n",
        "        if stage == 3:  # If it's the third stage, no further actions are possible\n",
        "            return []\n",
        "        actions = ['hit', 'stick', 'double_down']\n",
        "        if can_split and player_sum_1_range % 2 == 0 and stage == 1:\n",
        "            actions.append('split')\n",
        "        return actions\n",
        "\n",
        "    def get_reward(self, player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, done_split):\n",
        "        \"\"\"\n",
        "        Calculate the reward for a given state.\n",
        "        \"\"\"\n",
        "        if done_split == 0 and stage == 3:\n",
        "            dupla = 0\n",
        "            if dd1 == 0:\n",
        "              dupla = 1\n",
        "            else:\n",
        "              dupla = 2 * dd1\n",
        "\n",
        "            if player_sum_1 > 21 and dealer_sum == 21 or dealer_sum == 21 and player_sum_1 < 21 or dealer_sum < 21 and player_sum_1 > 21:\n",
        "                  return -1 * dupla\n",
        "            elif player_sum_1 == 21 and dealer_sum > 21 or dealer_sum < 21 and player_sum_1 == 21 or dealer_sum > 21 and player_sum_1 < 21:\n",
        "                  return 1 * dupla\n",
        "\n",
        "            elif player_sum_1 == 21 and dealer_sum == 21 or dealer_sum > 21 and player_sum_1 > 21:\n",
        "                  return 0\n",
        "\n",
        "            else:\n",
        "              diff_21_player = 21 - player_sum_1\n",
        "              diff_21_dealer = 21 - dealer_sum\n",
        "              if diff_21_player > diff_21_dealer:\n",
        "                  return -1 * dupla\n",
        "              elif diff_21_player < diff_21_dealer:\n",
        "                  return 1 * dupla\n",
        "              else:\n",
        "                  return 0\n",
        "\n",
        "        elif done_split == 1 and stage == 3:\n",
        "            dupla1 = 0\n",
        "            dupla2 = 0\n",
        "            if dd1 == 0:\n",
        "              dupla1 = 1\n",
        "            else:\n",
        "              dupla1 = 2 * dd1\n",
        "            if dd2 == 0:\n",
        "              dupla2 = 1\n",
        "            else:\n",
        "              dupla2 = 2 * dd2\n",
        "\n",
        "            #if mode == 'normal':\n",
        "            if player_sum_1 == 21 and player_sum_2 == 21 and dealer_sum == 21 or player_sum_1 > 21 and player_sum_2 > 21 and dealer_sum > 21:\n",
        "                return 0\n",
        "\n",
        "            elif dealer_sum > 21 and player_sum_1 <= 21 and player_sum_2 <= 21 or player_sum_1 == 21 and player_sum_2 == 21 and dealer_sum < 21:\n",
        "                return 1 * dupla1 + 1 * dupla2\n",
        "\n",
        "            elif dealer_sum == 21 and player_sum_1 and player_sum_2 < 21 or dealer_sum <= 21 and player_sum_1 > 21 and player_sum_2 > 21 or dealer_sum == 21 and player_sum_1 < 21 and player_sum_2 > 21 or dealer_sum == 21 and player_sum_1 > 21 and player_sum_2 < 21:\n",
        "                return -1 * dupla1 -1 * dupla2\n",
        "\n",
        "            elif dealer_sum == 21 and player_sum_1 < 21 and player_sum_2 == 21 or dealer_sum == 21 and player_sum_1 > 21 and player_sum_2 == 21:\n",
        "                return -1 * dupla1\n",
        "\n",
        "            elif dealer_sum == 21 and player_sum_1 == 21 and player_sum_2 < 21 or dealer_sum == 21 and player_sum_1 == 21 and player_sum_2 > 21:\n",
        "                return -1 * dupla2\n",
        "\n",
        "            elif dealer_sum > 21 and player_sum_1 < 21 and player_sum_2 > 21 or dealer_sum > 21 and player_sum_1 == 21 and player_sum_2 > 21:\n",
        "                return 1 * dupla1\n",
        "\n",
        "            elif dealer_sum > 21 and player_sum_1 > 21 and player_sum_2 < 21 or dealer_sum > 21 and player_sum_1 > 21 and player_sum_2 == 21:\n",
        "                return 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 == 21 and player_sum_2 > 21:\n",
        "                return 1 * dupla1 - 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 > 21 and player_sum_2 == 21:\n",
        "                return -1 * dupla1 + 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 > 21 and player_sum_2 < 21:\n",
        "                if player_sum_2 - dealer_sum > 0:\n",
        "                    return -1 * dupla1 + 1 * dupla2\n",
        "                elif player_sum_2 - dealer_sum == 0:\n",
        "                    return -1 * dupla1\n",
        "                else:\n",
        "                    return -1 * dupla1 - 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 < 21 and player_sum_2 > 21:\n",
        "                if player_sum_1 - dealer_sum > 0:\n",
        "                    return 1 * dupla1 - 1 * dupla2\n",
        "                elif player_sum_1 - dealer_sum == 0:\n",
        "                    return -1 * dupla2\n",
        "                else:\n",
        "                    return -1 * dupla1 - 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 < 21 and player_sum_2 == 21:\n",
        "                if player_sum_1 - dealer_sum > 0:\n",
        "                    return 1 * dupla1 + 1 * dupla2\n",
        "                elif player_sum_1 - dealer_sum == 0:\n",
        "                    return 1 * dupla2\n",
        "                else:\n",
        "                    return -1 * dupla1 + 1 * dupla2\n",
        "\n",
        "            elif dealer_sum < 21 and player_sum_1 == 21 and player_sum_2 < 21:\n",
        "                if player_sum_2 - dealer_sum > 0:\n",
        "                    return 1 * dupla1 + 1 * dupla2\n",
        "                elif player_sum_2 - dealer_sum == 0:\n",
        "                    return 1 * dupla1\n",
        "                else:\n",
        "                    return 1 * dupla1 - 1 * dupla2\n",
        "\n",
        "            else:\n",
        "                diff_21_player1 = 21 - player_sum_1\n",
        "                diff_21_player2 = 21 - player_sum_2\n",
        "                diff_21_dealer = 21 - dealer_sum\n",
        "\n",
        "                if diff_21_player1 > diff_21_dealer and diff_21_player2 > diff_21_dealer:\n",
        "                    return -1 * dupla1 - 1 * dupla2\n",
        "                elif diff_21_player1 < diff_21_dealer and diff_21_player2 < diff_21_dealer:\n",
        "                    return 1 * dupla1 + 1 * dupla2\n",
        "                elif diff_21_player1 < diff_21_dealer and diff_21_player2 > diff_21_dealer:\n",
        "                    return 1 * dupla1 - 1 * dupla2\n",
        "                else:\n",
        "                    return -1 * dupla1 + 1 * dupla2\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def get_transition_probabilities(self, state, action):\n",
        "        \"\"\"\n",
        "        Calculate transition probabilities for a given state-action pair.\n",
        "        \"\"\"\n",
        "        distr = [1 / 13] * 8 + [4 / 13] + [1 / 13]  # Probabilities for cards 2–11\n",
        "        card_values = list(range(2, 12))  # Cards are valued from 2 to 11\n",
        "        distr_dict = {card_values[i]: distr[i] for i in range(len(card_values))}\n",
        "\n",
        "        transitions = []\n",
        "        player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done = state\n",
        "\n",
        "        if action == 'hit':\n",
        "            if stage == 1:\n",
        "              if split_done == 0:\n",
        "                if player_sum_1 >= 21:\n",
        "                  pass\n",
        "                  \"\"\"stage = 3\n",
        "                  next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                  reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                  transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "                else:\n",
        "                  for card, prob in distr_dict.items():\n",
        "                    new_sum = player_sum_1 + card\n",
        "                    new_ace_1 = ace_1\n",
        "                    if new_sum > 21 and new_ace_1:\n",
        "                        new_sum -= 10\n",
        "                        new_ace_1 = False\n",
        "                    if card == 11 and player_sum_1 < 11 and not new_ace_1:\n",
        "                       new_ace_1 = True\n",
        "                    if new_sum >= 21:\n",
        "                      stage = 3\n",
        "                      next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                      reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                      transitions.append((next_state, prob, reward))\n",
        "                    else:\n",
        "                      next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                      reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                      transitions.append((next_state, prob, reward))\n",
        "              else:\n",
        "                if player_sum_1 >= 21:\n",
        "                  pass\n",
        "                  \"\"\"stage = 2\n",
        "                  next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                  reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                  transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "                else:\n",
        "                  for card, prob in distr_dict.items():\n",
        "                    new_sum = player_sum_1 + card\n",
        "                    new_ace_1 = ace_1\n",
        "                    if new_sum > 21 and ace_1:\n",
        "                        new_sum -= 10\n",
        "                        new_ace_1 = False\n",
        "                    if card == 11 and player_sum_1 < 11 and not new_ace_1:\n",
        "                       new_ace_1 = True\n",
        "                    if new_sum >= 21:\n",
        "                      stage = 2\n",
        "                      next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                      reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                      transitions.append((next_state, prob, reward))\n",
        "                    else:\n",
        "                      next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                      reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                      transitions.append((next_state, prob, reward))\n",
        "            elif stage == 2:\n",
        "              if player_sum_2 >= 21:\n",
        "                pass\n",
        "                \"\"\"stage = 3\n",
        "                next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "              else:\n",
        "                for card, prob in distr_dict.items():\n",
        "                  new_sum = player_sum_2 + card\n",
        "                  new_ace_2 = ace_2\n",
        "                  if new_sum > 21 and ace_2:\n",
        "                      new_sum -= 10\n",
        "                      new_ace_2 = False\n",
        "                  if card == 11 and player_sum_2 < 11 and not new_ace_2:\n",
        "                       new_ace_2 = True\n",
        "                  if new_sum >= 21:\n",
        "                    stage = 3\n",
        "                    next_state = (player_sum_1, new_sum, dealer_sum, stage, ace_1, new_ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                    reward = self.get_reward(player_sum_1, new_sum, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                    transitions.append((next_state, prob, reward))\n",
        "                  else:\n",
        "                    next_state = (player_sum_1, new_sum, dealer_sum, stage, ace_1, new_ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                    reward = self.get_reward(player_sum_1, new_sum, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                    transitions.append((next_state, prob, reward))\n",
        "\n",
        "        elif action == 'stick': # usable ace for the dealer?\n",
        "            if split_done == 0:\n",
        "              if stage == 1:\n",
        "                if dealer_sum < 18:\n",
        "                  for card, prob in distr_dict.items():\n",
        "                    new_dealer_sum = dealer_sum + card\n",
        "                    if stick_happened == False:\n",
        "                      stick_happened = True\n",
        "                    new_stage = 3\n",
        "                    next_state = (player_sum_1, player_sum_2, new_dealer_sum, new_stage, ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                    transitions.append((next_state, 1.0, self.get_reward(player_sum_1, player_sum_2, new_dealer_sum, new_stage, dd1, dd2, split_done)))\n",
        "                else:\n",
        "                  pass\n",
        "                  \"\"\"new_stage = 3\n",
        "                  next_state = (player_sum_1, player_sum_2, dealer_sum, new_stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                  transitions.append((next_state, 1.0, self.get_reward(player_sum_1, player_sum_2, dealer_sum, new_stage, dd1, dd2, split_done)))\"\"\"\n",
        "\n",
        "            else:\n",
        "              if stage == 1:\n",
        "                new_stage = 2\n",
        "                next_state = (player_sum_1, player_sum_2, dealer_sum, new_stage, ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                transitions.append((next_state, 1.0, self.get_reward(player_sum_1, player_sum_2, dealer_sum, new_stage, dd1, dd2, split_done)))\n",
        "              elif stage == 2:\n",
        "                if dealer_sum < 18:\n",
        "                  for card, prob in distr_dict.items():\n",
        "                    new_dealer_sum = dealer_sum + card\n",
        "                    if stick_happened == False:\n",
        "                       stick_happened = True\n",
        "                    new_stage = 3\n",
        "                    next_state = (player_sum_1, player_sum_2, new_dealer_sum, new_stage, ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                    transitions.append((next_state, 1.0, self.get_reward(player_sum_1, player_sum_2, new_dealer_sum, new_stage, dd1, dd2, split_done)))\n",
        "                else:\n",
        "                  pass\n",
        "                  \"\"\"new_stage = 3\n",
        "                  next_state = (player_sum_1, player_sum_2, dealer_sum, new_stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                  transitions.append((next_state, 1.0, self.get_reward(player_sum_1, player_sum_2, dealer_sum, new_stage, dd1, dd2, split_done)))\"\"\"\n",
        "\n",
        "        elif action == 'double_down':\n",
        "          if stage == 1 and dd1 == 0:\n",
        "            if split_done == 0:\n",
        "              if player_sum_1 >= 21:\n",
        "                pass\n",
        "                \"\"\"stage = 3\n",
        "                next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "              else:\n",
        "                dd1 = 1\n",
        "                for card, prob in distr_dict.items():\n",
        "                  new_sum = player_sum_1 + card\n",
        "                  new_ace_1 = ace_1\n",
        "                  if new_sum > 21 and ace_1:\n",
        "                      new_sum -= 10\n",
        "                      new_ace_1 = False\n",
        "                  if card == 11 and player_sum_1 < 11 and not new_ace_1:\n",
        "                       new_ace_1 = True\n",
        "                  stage = 3\n",
        "                  next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                  reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                  transitions.append((next_state, 1.0, reward))\n",
        "            else:\n",
        "              dd1 = 1\n",
        "              if player_sum_1 >= 21:\n",
        "                pass\n",
        "                \"\"\"stage = 2\n",
        "                next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "                reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "              else:\n",
        "                for card, prob in distr_dict.items():\n",
        "                  new_sum = player_sum_1 + card\n",
        "                  new_ace_1 = ace_1\n",
        "                  if new_sum > 21 and ace_1:\n",
        "                      new_sum -= 10\n",
        "                      new_ace_1 = False\n",
        "                  if card == 11 and player_sum_1 < 11 and not new_ace_1:\n",
        "                       new_ace_1 = True\n",
        "                  stage = 2\n",
        "                  next_state = (new_sum, player_sum_2, dealer_sum, stage, new_ace_1, ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                  reward = self.get_reward(new_sum, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                  transitions.append((next_state, 1.0, reward))\n",
        "\n",
        "          elif stage == 2 and dd2 == 0:\n",
        "            dd2 = 1\n",
        "            if player_sum_2 >= 21:\n",
        "              pass\n",
        "              \"\"\"stage = 3\n",
        "              next_state = (player_sum_1, player_sum_2, dealer_sum, stage, ace_1, ace_2, dd1, dd2, can_split, split_done)\n",
        "              reward = self.get_reward(player_sum_1, player_sum_2, dealer_sum, stage, dd1, dd2, split_done)\n",
        "              transitions.append((next_state, 1.0, reward))\"\"\"\n",
        "            else:\n",
        "              for card, prob in distr_dict.items():\n",
        "                new_sum = player_sum_2 + card\n",
        "                new_ace_2 = ace_2\n",
        "                if new_sum > 21 and ace_2:\n",
        "                    new_sum -= 10\n",
        "                    new_ace_2 = False\n",
        "                if card == 11 and player_sum_2 < 11 and not new_ace_2:\n",
        "                  new_ace_2 = True\n",
        "                stage = 3\n",
        "                next_state = (player_sum_1, new_sum, dealer_sum, stage, ace_1, new_ace_2, stick_happened, dd1, dd2, can_split, split_done)\n",
        "                reward = self.get_reward(player_sum_1, new_sum, dealer_sum, stage, dd1, dd2, split_done)\n",
        "                transitions.append((next_state, 1.0, reward))\n",
        "\n",
        "        elif action == 'split':\n",
        "            if can_split and stage == 1 and not split_done and not ace_1 and not ace_2 and dd1 == 0 and dd2 == 0 and dealer_sum <= 17:\n",
        "                split_state = (player_sum_1 // 2, player_sum_1 // 2, dealer_sum, stage, ace_1, ace_2, stick_happened, dd1, dd2, 0, 1)\n",
        "                transitions.append((split_state, 1.0, 0))  # No immediate reward for splitting\n",
        "\n",
        "        return transitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXUzyYBldKDn"
      },
      "outputs": [],
      "source": [
        "bj = Sol_Env()\n",
        "#len(bj.get_all_states())\n",
        "#bj.get_all_states()[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRiyg6u_02b1"
      },
      "source": [
        "Value iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd7Y8HsLcqQC"
      },
      "outputs": [],
      "source": [
        "def value_iteration_to_get_opt_solution(env, n = 10000, theta=1e-10):\n",
        "    \"\"\"Perform value iteration to find the optimal policy.\"\"\"\n",
        "    # Get all states and filter out terminal ones\n",
        "    all_states = env.get_all_states()\n",
        "    non_terminal_states = [state for state in all_states if state[3] != 3]\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states = [\n",
        "    (2, 2, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "    for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "    for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states\n",
        "\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states2 = [\n",
        "        (3, 3, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "        for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "        for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states2\n",
        "\n",
        "    V = {state: 0 for state in all_states}  # Initialize value function\n",
        "    policy = {state: None for state in all_states}  # Initialize policy\n",
        "\n",
        "    iterations = 0\n",
        "    delta_list = []  # To track convergence\n",
        "\n",
        "    while iterations != n:\n",
        "        delta = 0\n",
        "        W = V\n",
        "        for state in non_terminal_states:\n",
        "            old_value = V[state]\n",
        "            max_value = float('-inf')\n",
        "            best_action = None\n",
        "            #print(state)\n",
        "            for action in env.get_possible_actions(state):\n",
        "                #print(action)\n",
        "                transitions = env.get_transition_probabilities(state, action)\n",
        "                #for i in transitions:\n",
        "                  #print(i)\n",
        "                action_value = sum(\n",
        "                    prob * (reward + W[next_state])\n",
        "                    for next_state, prob, reward in transitions\n",
        "                )\n",
        "                \"\"\"action_value = 0\n",
        "                for next_state, prob, reward in transitions:\n",
        "                  print(f\"Transition: next_state={next_state}, prob={prob}, reward={reward}\")\n",
        "                  action_value += prob * (reward + gamma * V[next_state])\"\"\"\n",
        "                if action_value > max_value:\n",
        "                    max_value = action_value\n",
        "                    best_action = action\n",
        "\n",
        "            V[state] = max_value\n",
        "            policy[state] = best_action\n",
        "            delta = max(delta, abs(old_value - V[state]))\n",
        "\n",
        "        delta_list.append(delta)\n",
        "        iterations += 1\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    return V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06QaX9WpcqWK"
      },
      "outputs": [],
      "source": [
        "V_opt = value_iteration_to_get_opt_solution(bj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJYMyUV204kD"
      },
      "outputs": [],
      "source": [
        "def value_iteration(env, V_opt, n = 10000, theta=1e-6):\n",
        "    \"\"\"Perform value iteration to find the optimal policy.\"\"\"\n",
        "    # Get all states and filter out terminal ones\n",
        "    all_states = env.get_all_states()\n",
        "    non_terminal_states = [state for state in all_states if state[3] != 3]\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states = [\n",
        "    (2, 2, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "    for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "    for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states\n",
        "\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states2 = [\n",
        "        (3, 3, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "        for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "        for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states2\n",
        "\n",
        "    V = {state: 0 for state in all_states}  # Initialize value function\n",
        "    policy = {state: None for state in all_states}  # Initialize policy\n",
        "\n",
        "    iterations = 0\n",
        "    delta_list = []  # To track convergence\n",
        "\n",
        "    while iterations != n:\n",
        "        W = V\n",
        "        for state in non_terminal_states:\n",
        "            old_value = V[state]\n",
        "            max_value = float('-inf')\n",
        "            best_action = None\n",
        "            #print(state)\n",
        "            for action in env.get_possible_actions(state):\n",
        "                #print(action)\n",
        "                transitions = env.get_transition_probabilities(state, action)\n",
        "                #for i in transitions:\n",
        "                  #print(i)\n",
        "                action_value = sum(\n",
        "                    prob * (reward + W[next_state])\n",
        "                    for next_state, prob, reward in transitions\n",
        "                )\n",
        "                \"\"\"action_value = 0\n",
        "                for next_state, prob, reward in transitions:\n",
        "                  print(f\"Transition: next_state={next_state}, prob={prob}, reward={reward}\")\n",
        "                  action_value += prob * (reward + gamma * V[next_state])\"\"\"\n",
        "                if action_value > max_value:\n",
        "                    max_value = action_value\n",
        "                    best_action = action\n",
        "\n",
        "            V[state] = max_value\n",
        "            policy[state] = best_action\n",
        "\n",
        "        diff = max(abs(V_opt[key] - V[key]) for key in V)\n",
        "        delta_list.append(diff)\n",
        "        iterations += 1\n",
        "        if diff < theta:\n",
        "            break\n",
        "\n",
        "    return V, policy, iterations, delta_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt-FzhLV04rD"
      },
      "outputs": [],
      "source": [
        "bj = Sol_Env()\n",
        "start_time = time.time()\n",
        "V_vi, policy_vi, iterations_vi, deltas_vi = value_iteration(bj, V_opt)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Value Iteration completed in {end_time - start_time:.2f} seconds and {iterations_vi} iterations.\")\n",
        "# Plot convergence\n",
        "def plot_convergence(deltas, label, name):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(deltas)\n",
        "    #plt.plot(range(1, len(deltas)+1), deltas)\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Delta')\n",
        "    plt.title(label)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(name, format=\"jpg\", dpi=300)\n",
        "    plt.show()\n",
        "plot_convergence(deltas_vi, 'Convergence of Value Iteration', \"value_iteration.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8UuCaqhzpec"
      },
      "source": [
        "Gauss-Seidel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn9sNRP6n8T5"
      },
      "outputs": [],
      "source": [
        "def gauss_seidel(env, V_opt, n = 10000, theta=1e-6):\n",
        "    \"\"\"Perform value iteration to find the optimal policy.\"\"\"\n",
        "    # Get all states and filter out terminal ones\n",
        "    all_states = env.get_all_states()\n",
        "    non_terminal_states = [state for state in all_states if state[3] != 3]\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states = [\n",
        "    (2, 2, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "    for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "    for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states\n",
        "\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states2 = [\n",
        "        (3, 3, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "        for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "        for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states2\n",
        "\n",
        "    V = {state: 0 for state in all_states}  # Initialize value function\n",
        "    policy = {state: None for state in all_states}  # Initialize policy\n",
        "\n",
        "    iterations = 0\n",
        "    delta_list = []  # To track convergence\n",
        "\n",
        "    while iterations != n:\n",
        "        for state in non_terminal_states:\n",
        "            old_value = V[state]\n",
        "            max_value = float('-inf')\n",
        "            best_action = None\n",
        "            #print(state)\n",
        "            for action in env.get_possible_actions(state):\n",
        "                #print(action)\n",
        "                transitions = env.get_transition_probabilities(state, action)\n",
        "                #for i in transitions:\n",
        "                  #print(i)\n",
        "                action_value = sum(\n",
        "                    prob * (reward + V[next_state])\n",
        "                    for next_state, prob, reward in transitions\n",
        "                )\n",
        "                \"\"\"action_value = 0\n",
        "                for next_state, prob, reward in transitions:\n",
        "                  print(f\"Transition: next_state={next_state}, prob={prob}, reward={reward}\")\n",
        "                  action_value += prob * (reward + gamma * V[next_state])\"\"\"\n",
        "                if action_value > max_value:\n",
        "                    max_value = action_value\n",
        "                    best_action = action\n",
        "\n",
        "            V[state] = max_value\n",
        "            policy[state] = best_action\n",
        "\n",
        "        diff = max(abs(V_opt[key] - V[key]) for key in V)\n",
        "        delta_list.append(diff)\n",
        "        iterations += 1\n",
        "        if diff < theta:\n",
        "            break\n",
        "\n",
        "    return V, policy, iterations, delta_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ffOzzYaSiVh"
      },
      "outputs": [],
      "source": [
        "# Main Execution\n",
        "bj = Sol_Env()\n",
        "\n",
        "start_time = time.time()\n",
        "V_gs, policy_gs, iterations_gs, deltas_gs = gauss_seidel(bj, V_opt)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Gauss-Seidel completed in {end_time - start_time:.2f} seconds and {iterations_gs} iterations.\")\n",
        "#print(deltas)\n",
        "plot_convergence(deltas_gs, 'Convergence of Gauss-Seidel', \"gauss-seidel.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq5P2dnGoBvB"
      },
      "source": [
        "Optimistic Policy iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w3La-wnoB0Z"
      },
      "outputs": [],
      "source": [
        "def opt_policy_iteration(env, V_opt, n1=50, theta=1e-6, gamma=0.9):\n",
        "    \"\"\"Perform policy iteration to find the optimal policy.\"\"\"\n",
        "    all_states = env.get_all_states()\n",
        "    non_terminal_states = [state for state in all_states if state[3] != 3]\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states = [\n",
        "    (2, 2, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "    for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "    for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states\n",
        "\n",
        "    # Define additional states to include in V and policy\n",
        "    additional_states2 = [\n",
        "        (3, 3, dealer_card, 1, 0, 0, dealer_ace, 0, 0, 0, 1)\n",
        "        for dealer_card in range(4, 27)  # Iterate over all possible dealer cards\n",
        "        for dealer_ace in [False, True]  # Iterate over both possible values of dealer_ace\n",
        "    ]\n",
        "\n",
        "    # Combine all states\n",
        "    all_states += additional_states2\n",
        "\n",
        "    # Initialize policy and value function\n",
        "    policy = {}\n",
        "    for state in all_states:\n",
        "        possible_actions = env.get_possible_actions(state)\n",
        "        if possible_actions:  # Ensure there are valid actions\n",
        "            policy[state] = possible_actions[0]  # Default to the first action\n",
        "        else:\n",
        "            policy[state] = None  # No action for terminal states\n",
        "\n",
        "    V = {state: 0 for state in all_states}\n",
        "\n",
        "    iterations1 = 0  # To track convergence iterations\n",
        "    delta_list = []  # To track convergence\n",
        "    delta_list2 = []\n",
        "\n",
        "    while True:  # Policy Iteration\n",
        "        # Policy Evaluation\n",
        "        delta_help = []\n",
        "        while True:\n",
        "            delta = 0\n",
        "            for state in non_terminal_states:\n",
        "                old_value = V[state]\n",
        "                action = policy[state]\n",
        "\n",
        "                if action is None:\n",
        "                    continue  # Skip states with no valid action\n",
        "\n",
        "                transitions = env.get_transition_probabilities(state, action)\n",
        "\n",
        "                if not transitions:\n",
        "                    continue  # Skip if no transitions exist\n",
        "\n",
        "                # Use proper gamma (not 0.01)\n",
        "                V[state] = sum(prob * (reward + V[next_state])\n",
        "                               for next_state, prob, reward in transitions)\n",
        "\n",
        "                delta = max(delta, abs(old_value - V[state]))\n",
        "                #print(delta)\n",
        "\n",
        "            diff = max(abs(V_opt[key] - V[key]) for key in V)\n",
        "            #print(diff)\n",
        "            delta_list.append(diff)\n",
        "            delta_help.append(diff)\n",
        "\n",
        "            if delta < theta:\n",
        "                break  # Converged\n",
        "\n",
        "        # Policy Improvement\n",
        "        policy_stable = True\n",
        "        for state in non_terminal_states:\n",
        "            old_action = policy[state]\n",
        "            max_value = float('-inf')\n",
        "            best_action = None\n",
        "\n",
        "            for action in env.get_possible_actions(state):\n",
        "                transitions = env.get_transition_probabilities(state, action)\n",
        "                if not transitions:\n",
        "                    continue\n",
        "\n",
        "                action_value = sum(prob * (reward + V[next_state])\n",
        "                                   for next_state, prob, reward in transitions)\n",
        "\n",
        "                if action_value > max_value:\n",
        "                    max_value = action_value\n",
        "                    best_action = action\n",
        "\n",
        "            if best_action is not None:\n",
        "                policy[state] = best_action\n",
        "                if old_action != best_action:\n",
        "                    policy_stable = False\n",
        "\n",
        "        delta_list2.append(delta_help)\n",
        "        iterations1 += 1\n",
        "        print(f\"Iteration: {iterations1}\")\n",
        "\n",
        "        if iterations1 == n1:\n",
        "            break\n",
        "\n",
        "    return V, policy, iterations1, delta_list, delta_list2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwAmOypwDfba"
      },
      "outputs": [],
      "source": [
        "bj = Sol_Env()\n",
        "\n",
        "start_time = time.time()\n",
        "V_pi, policy_pi, iterations_pi, deltas_pi, deltas2_pi = opt_policy_iteration(bj, V_opt)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Optimistic Policy Iteration completed in {end_time - start_time:.2f} seconds and {iterations_pi} iterations.\")\n",
        "#print(deltas)\n",
        "plot_convergence(deltas_pi, 'Convergence of Policy Iteration', 's.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz95LJ13zroE"
      },
      "outputs": [],
      "source": [
        "def plot_convergence_continuous(deltas2):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    cumulative_index = 0  # Initialize the cumulative index\n",
        "    full_x = []  # To store the continuous x-axis\n",
        "    full_y = []  # To store the continuous y-axis\n",
        "\n",
        "    for i, sublist in enumerate(deltas2, start=1):\n",
        "        # Compute the range of x values for the sublist\n",
        "        x_range = list(range(cumulative_index, cumulative_index + len(sublist)))\n",
        "\n",
        "        # Extend the full x and y lists\n",
        "        full_x.extend(x_range)\n",
        "        full_y.extend(sublist)\n",
        "\n",
        "        # Calculate the mid-point of the y values in the current segment\n",
        "        segment_y_min = min(full_y)\n",
        "        segment_y_max = max(full_y)\n",
        "        segment_y_mid = (segment_y_min + segment_y_max) / 2\n",
        "\n",
        "        # Update cumulative index\n",
        "        cumulative_index += len(sublist)\n",
        "\n",
        "        # Add a vertical line at the cumulative last index of the sublist\n",
        "        plt.axvline(x=cumulative_index - 1, color='red', linestyle='--')\n",
        "\n",
        "        # Add a label near the vertical line, centered vertically\n",
        "        plt.text(cumulative_index - 1 + 0.2, segment_y_mid, f\"Evaluation Iteration {i}\",\n",
        "                 color='red', fontsize=10, ha='left', va='center')\n",
        "\n",
        "    # Plot the continuous data\n",
        "    plt.plot(full_x, full_y)\n",
        "\n",
        "    plt.xlabel('Improvement Iterations')\n",
        "    plt.ylabel('Delta')\n",
        "    plt.title('Convergence of Optimistic Policy Iteration')\n",
        "    plt.grid()\n",
        "    plt.savefig(\"opt_policy_iteration.jpg\", format=\"jpg\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "plot_convergence_continuous(deltas2_pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMvTNNUZj822"
      },
      "source": [
        "###Additional stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7Bci8mYj50-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data from the user\n",
        "distr = [1 / 13] * 8 + [4 / 13] + [1 / 13]  # Probabilities for cards 2–11\n",
        "card_values = list(range(2, 12))  # Cards are valued from 2 to 11\n",
        "distr_dict = {card_values[i]: distr[i] for i in range(len(card_values))}\n",
        "\n",
        "# Creating the histogram plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(distr_dict.keys(), distr_dict.values(), color='skyblue', edgecolor='black')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel(\"Card Values\", fontsize=12)\n",
        "plt.ylabel(\"Probability\", fontsize=12)\n",
        "plt.title(\"Probability Distribution of Card Values\", fontsize=14)\n",
        "plt.xticks(card_values, fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adding values on top of the bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2,  # X position\n",
        "        height,  # Y position\n",
        "        f\"{height:.3f}\",  # Text to display\n",
        "        ha='center',  # Horizontal alignment\n",
        "        va='bottom',  # Vertical alignment\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "# Save the plot as a JPG or PNG file\n",
        "plt.savefig(\"probability_distribution_with_values.jpg\", format=\"jpg\", dpi=300)  # Save as JPG\n",
        "# plt.savefig(\"probability_distribution_with_values.png\", format=\"png\", dpi=300)  # Save as PNG\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}